{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: scikit-learn in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: pyaml in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (24.9.0)\n",
      "Requirement already satisfied: tensorboardX in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: PyYAML in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from pyaml) (6.0.2)\n",
      "Requirement already satisfied: packaging in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/wode/公共/wode/.venv/lib/python3.11/site-packages (from tensorboardX) (5.29.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pyaml tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "with open('data/data.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# 训练集，测试集索引\n",
    "train_idx, test_idx = train_test_split(range(len(data[0])), test_size=0.2, random_state=42)\n",
    "\n",
    "train = [[] for _ in data]\n",
    "test = [[] for _ in data]\n",
    "\n",
    "for i,snr in enumerate(data):\n",
    "    for j in range(len(snr)):\n",
    "        if j in train_idx:\n",
    "            train[i].append(snr[j])\n",
    "        elif j in test_idx:\n",
    "            test[i].append(snr[j])\n",
    "\n",
    "with open('data/train.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)\n",
    "with open('data/test.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_snr(模态判断)\n",
    "\n",
    "`BEST ACC@1：99.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/snr', 'config': 'config/train_snr.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_snr', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl'}, 'test_feeder_args': {'data_path': './data/test.pkl'}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 3}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 61.86118588094174 Mean loss: 61.86099450263751 LR: [0.00095]\n",
      "Eval MSE: 61.523743406825716\n",
      "Eval Best MSE: 61.523743406825716\n",
      "Epoch:[2/80]\n",
      "Train MSE: 61.463721971074094 Mean loss: 61.4625916339942 LR: [0.0009025]\n",
      "Eval MSE: 61.49030817944254\n",
      "Eval Best MSE: 61.49030817944254\n",
      "Epoch:[3/80]\n",
      "Train MSE: 61.33797444724971 Mean loss: 61.338311054297456 LR: [0.000857375]\n",
      "Eval MSE: 61.35992337931451\n",
      "Eval Best MSE: 61.35992337931451\n",
      "Epoch:[4/80]\n",
      "Train MSE: 61.30369571699464 Mean loss: 61.30262985455214 LR: [0.0008145062499999999]\n",
      "Eval MSE: 61.35863783339241\n",
      "Eval Best MSE: 61.35863783339241\n",
      "Epoch:[5/80]\n",
      "Train MSE: 61.30253702199642 Mean loss: 61.299501966442584 LR: [0.0007737809374999998]\n",
      "Eval MSE: 61.35205067963764\n",
      "Eval Best MSE: 61.35205067963764\n",
      "Epoch:[6/80]\n",
      "Train MSE: 61.29133556329359 Mean loss: 61.29122078348194 LR: [0.0007350918906249997]\n",
      "Eval MSE: 61.34582266629382\n",
      "Eval Best MSE: 61.34582266629382\n",
      "Epoch:[7/80]\n",
      "Train MSE: 61.288981661673624 Mean loss: 61.288392687690326 LR: [0.0006983372960937497]\n",
      "Eval MSE: 61.34464444842464\n",
      "Eval Best MSE: 61.34464444842464\n",
      "Epoch:[8/80]\n",
      "Train MSE: 61.288042970662424 Mean loss: 61.28883898469823 LR: [0.0006634204312890621]\n",
      "Eval MSE: 61.34279289908908\n",
      "Eval Best MSE: 61.34279289908908\n",
      "Epoch:[9/80]\n",
      "Train MSE: 61.28779528217931 Mean loss: 61.286864749073274 LR: [0.000630249409724609]\n",
      "Eval MSE: 61.34287775387554\n",
      "Eval Best MSE: 61.34279289908908\n",
      "Epoch:[10/80]\n",
      "Train MSE: 61.2826879678868 Mean loss: 61.28355571363099 LR: [0.0005987369392383785]\n",
      "Eval MSE: 61.33329706336673\n",
      "Eval Best MSE: 61.33329706336673\n",
      "Epoch:[11/80]\n",
      "Train MSE: 61.27357135419419 Mean loss: 61.2747509578276 LR: [0.0005688000922764595]\n",
      "Eval MSE: 61.305810584697376\n",
      "Eval Best MSE: 61.305810584697376\n",
      "Epoch:[12/80]\n",
      "Train MSE: 61.24942261802487 Mean loss: 61.249213342835915 LR: [0.0005403600876626365]\n",
      "Eval MSE: 61.30560459104503\n",
      "Eval Best MSE: 61.30560459104503\n",
      "Epoch:[13/80]\n",
      "Train MSE: 61.24864206392375 Mean loss: 61.25003248135719 LR: [0.0005133420832795047]\n",
      "Eval MSE: 61.30472354416136\n",
      "Eval Best MSE: 61.30472354416136\n",
      "Epoch:[14/80]\n",
      "Train MSE: 61.24799924072661 Mean loss: 61.24631951687604 LR: [0.00048767497911552944]\n",
      "Eval MSE: 61.30450086067925\n",
      "Eval Best MSE: 61.30450086067925\n",
      "Epoch:[15/80]\n",
      "Train MSE: 61.24796179697436 Mean loss: 61.24620828684971 LR: [0.00046329123015975297]\n",
      "Eval MSE: 61.30406436786094\n",
      "Eval Best MSE: 61.30406436786094\n",
      "Epoch:[16/80]\n",
      "Train MSE: 61.247892868407185 Mean loss: 61.2485607305222 LR: [0.0004401266686517653]\n",
      "Eval MSE: 61.30379677736182\n",
      "Eval Best MSE: 61.30379677736182\n",
      "Epoch:[17/80]\n",
      "Train MSE: 61.247758278619045 Mean loss: 61.24715840604884 LR: [0.00041812033521917703]\n",
      "Eval MSE: 61.304105597075115\n",
      "Eval Best MSE: 61.30379677736182\n",
      "Epoch:[18/80]\n",
      "Train MSE: 61.247613292159976 Mean loss: 61.24714333912325 LR: [0.00039721431845821814]\n",
      "Eval MSE: 61.3034013810971\n",
      "Eval Best MSE: 61.3034013810971\n",
      "Epoch:[19/80]\n",
      "Train MSE: 61.24763308218662 Mean loss: 61.24859803668141 LR: [0.0003773536025353072]\n",
      "Eval MSE: 61.30382185303367\n",
      "Eval Best MSE: 61.3034013810971\n",
      "Epoch:[20/80]\n",
      "Train MSE: 61.24764676852121 Mean loss: 61.24941407152887 LR: [0.0003584859224085418]\n",
      "Eval MSE: 61.30318854272343\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[21/80]\n",
      "Train MSE: 61.247587388649826 Mean loss: 61.24488826616276 LR: [0.0003405616262881147]\n",
      "Eval MSE: 61.303507509559694\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[22/80]\n",
      "Train MSE: 61.247534767615754 Mean loss: 61.24600903663409 LR: [0.00032353354497370894]\n",
      "Eval MSE: 61.30356800560593\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[23/80]\n",
      "Train MSE: 61.247532966164776 Mean loss: 61.244892013143506 LR: [0.00030735686772502346]\n",
      "Eval MSE: 61.30352566147838\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[24/80]\n",
      "Train MSE: 61.247426634598966 Mean loss: 61.24770421248216 LR: [0.00029198902433877225]\n",
      "Eval MSE: 61.30338469126733\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[25/80]\n",
      "Train MSE: 61.247363442676665 Mean loss: 61.24921871501313 LR: [0.00027738957312183364]\n",
      "Eval MSE: 61.30326098104428\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[26/80]\n",
      "Train MSE: 61.247291909671134 Mean loss: 61.24831544435941 LR: [0.0002635200944657419]\n",
      "Eval MSE: 61.3032268280018\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[27/80]\n",
      "Train MSE: 61.24729752687791 Mean loss: 61.24772357940674 LR: [0.0002503440897424548]\n",
      "Eval MSE: 61.303924806110075\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[28/80]\n",
      "Train MSE: 61.247279299161434 Mean loss: 61.248110212517915 LR: [0.00023782688525533205]\n",
      "Eval MSE: 61.30319559913717\n",
      "Eval Best MSE: 61.30318854272343\n",
      "Epoch:[29/80]\n",
      "Train MSE: 61.247277939825445 Mean loss: 61.2468359738412 LR: [0.00022593554099256544]\n",
      "Eval MSE: 61.30303881409166\n",
      "Eval Best MSE: 61.30303881409166\n",
      "Epoch:[30/80]\n",
      "Train MSE: 61.24724930582301 Mean loss: 61.247204120342545 LR: [0.00021463876394293716]\n",
      "Eval MSE: 61.30326228506954\n",
      "Eval Best MSE: 61.30303881409166\n",
      "Epoch:[31/80]\n",
      "Train MSE: 61.2472215071815 Mean loss: 61.24588633430075 LR: [0.0002039068257457903]\n",
      "Eval MSE: 61.3032123821116\n",
      "Eval Best MSE: 61.30303881409166\n",
      "Epoch:[32/80]\n",
      "Train MSE: 61.24720653613767 Mean loss: 61.24528261331412 LR: [0.00019371148445850077]\n",
      "Eval MSE: 61.303749900194084\n",
      "Eval Best MSE: 61.30303881409166\n",
      "Epoch:[33/80]\n",
      "Train MSE: 61.24718148642461 Mean loss: 61.24816741604777 LR: [0.00018402591023557573]\n",
      "Eval MSE: 61.30316617106933\n",
      "Eval Best MSE: 61.30303881409166\n",
      "Epoch:[34/80]\n",
      "Train MSE: 61.24713505261867 Mean loss: 61.246134154189974 LR: [0.00017482461472379692]\n",
      "Eval MSE: 61.30325448632108\n",
      "Eval Best MSE: 61.30303881409166\n",
      "Epoch:[35/80]\n",
      "Train MSE: 61.24713070909472 Mean loss: 61.245459714584804 LR: [0.00016608338398760707]\n",
      "Eval MSE: 61.30295350769472\n",
      "Eval Best MSE: 61.30295350769472\n",
      "Epoch:[36/80]\n",
      "Train MSE: 61.24715758584003 Mean loss: 61.246571473116 LR: [0.0001577792147882267]\n",
      "Eval MSE: 61.3029879063004\n",
      "Eval Best MSE: 61.30295350769472\n",
      "Epoch:[37/80]\n",
      "Train MSE: 61.2470784259981 Mean loss: 61.24611493962756 LR: [0.00014989025404881537]\n",
      "Eval MSE: 61.30321564499731\n",
      "Eval Best MSE: 61.30295350769472\n",
      "Epoch:[38/80]\n",
      "Train MSE: 61.24705221242527 Mean loss: 61.24590011461247 LR: [0.00014239574134637458]\n",
      "Eval MSE: 61.30302687463961\n",
      "Eval Best MSE: 61.30295350769472\n",
      "Epoch:[39/80]\n",
      "Train MSE: 61.247056578178466 Mean loss: 61.247132826133594 LR: [0.00013527595427905584]\n",
      "Eval MSE: 61.3033070001521\n",
      "Eval Best MSE: 61.30295350769472\n",
      "Epoch:[40/80]\n",
      "Train MSE: 61.246999618031 Mean loss: 61.24709388349183 LR: [0.00012851215656510304]\n",
      "Eval MSE: 61.303055314809534\n",
      "Eval Best MSE: 61.30295350769472\n",
      "Epoch:[41/80]\n",
      "Train MSE: 61.24699831664983 Mean loss: 61.248179870244314 LR: [0.00012208654873684788]\n",
      "Eval MSE: 61.30306119421346\n",
      "Eval Best MSE: 61.30295350769472\n",
      "Epoch:[42/80]\n",
      "Train MSE: 61.24698967529537 Mean loss: 61.2468738668769 LR: [0.00011598222130000548]\n",
      "Eval MSE: 61.302879641155734\n",
      "Eval Best MSE: 61.302879641155734\n",
      "Epoch:[43/80]\n",
      "Train MSE: 61.24696242197606 Mean loss: 61.24685224273501 LR: [0.00011018311023500519]\n",
      "Eval MSE: 61.302948579495364\n",
      "Eval Best MSE: 61.302879641155734\n",
      "Epoch:[44/80]\n",
      "Train MSE: 61.24695191151256 Mean loss: 61.24646270345654 LR: [0.00010467395472325493]\n",
      "Eval MSE: 61.30288097058408\n",
      "Eval Best MSE: 61.302879641155734\n",
      "Epoch:[45/80]\n",
      "Train MSE: 61.24692994928288 Mean loss: 61.247507727357764 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 61.3032784273216\n",
      "Eval Best MSE: 61.302879641155734\n",
      "Epoch:[46/80]\n",
      "Train MSE: 61.24690215999177 Mean loss: 61.24762359032264 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 61.30297648055528\n",
      "Eval Best MSE: 61.302879641155734\n",
      "Epoch:[47/80]\n",
      "Train MSE: 61.24688958961821 Mean loss: 61.24802986686752 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 61.30299572762939\n",
      "Eval Best MSE: 61.302879641155734\n",
      "Epoch:[48/80]\n",
      "Train MSE: 61.24687352925315 Mean loss: 61.24627436688666 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 61.30287661818809\n",
      "Eval Best MSE: 61.30287661818809\n",
      "Epoch:[49/80]\n",
      "Train MSE: 61.24684104562178 Mean loss: 61.24264330553585 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 61.30297377089241\n",
      "Eval Best MSE: 61.30287661818809\n",
      "Epoch:[50/80]\n",
      "Train MSE: 61.24682704604889 Mean loss: 61.24829220066409 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 61.30278924285064\n",
      "Eval Best MSE: 61.30278924285064\n",
      "Epoch:[51/80]\n",
      "Train MSE: 61.246466480192936 Mean loss: 61.245532752494135 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 61.301988139489474\n",
      "Eval Best MSE: 61.301988139489474\n",
      "Epoch:[52/80]\n",
      "Train MSE: 61.23178209491597 Mean loss: 61.23285272135537 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 61.27470303957788\n",
      "Eval Best MSE: 61.27470303957788\n",
      "Epoch:[53/80]\n",
      "Train MSE: 61.217523281041395 Mean loss: 61.216186602440104 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 61.2716932843625\n",
      "Eval Best MSE: 61.2716932843625\n",
      "Epoch:[54/80]\n",
      "Train MSE: 61.21589388054001 Mean loss: 61.21412637247842 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 61.27090638132833\n",
      "Eval Best MSE: 61.27090638132833\n",
      "Epoch:[55/80]\n",
      "Train MSE: 61.21548907548682 Mean loss: 61.21553252857818 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 61.27069262279831\n",
      "Eval Best MSE: 61.27069262279831\n",
      "Epoch:[56/80]\n",
      "Train MSE: 61.21502657998489 Mean loss: 61.21513685531165 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 61.27010772513144\n",
      "Eval Best MSE: 61.27010772513144\n",
      "Epoch:[57/80]\n",
      "Train MSE: 61.21470493886054 Mean loss: 61.21445886623225 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 61.27006578180819\n",
      "Eval Best MSE: 61.27006578180819\n",
      "Epoch:[58/80]\n",
      "Train MSE: 61.214583364912976 Mean loss: 61.21615089326215 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 61.270020682856725\n",
      "Eval Best MSE: 61.270020682856725\n",
      "Epoch:[59/80]\n",
      "Train MSE: 61.21451317368938 Mean loss: 61.21526942732771 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 61.26992359789398\n",
      "Eval Best MSE: 61.26992359789398\n",
      "Epoch:[60/80]\n",
      "Train MSE: 61.21448580498971 Mean loss: 61.215128227098454 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 61.26987710459515\n",
      "Eval Best MSE: 61.26987710459515\n",
      "Epoch:[61/80]\n",
      "Train MSE: 61.21443396215563 Mean loss: 61.21553336939163 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 61.269874857833024\n",
      "Eval Best MSE: 61.269874857833024\n",
      "Epoch:[62/80]\n",
      "Train MSE: 61.21441024725583 Mean loss: 61.21281793131631 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 61.26989928149224\n",
      "Eval Best MSE: 61.269874857833024\n",
      "Epoch:[63/80]\n",
      "Train MSE: 61.21439382160781 Mean loss: 61.21591377822605 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 61.26978472202652\n",
      "Eval Best MSE: 61.26978472202652\n",
      "Epoch:[64/80]\n",
      "Train MSE: 61.2143457106406 Mean loss: 61.21335477095384 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 61.26975086535342\n",
      "Eval Best MSE: 61.26975086535342\n",
      "Epoch:[65/80]\n",
      "Train MSE: 61.21434123294728 Mean loss: 61.21537036444308 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 61.269861507098234\n",
      "Eval Best MSE: 61.26975086535342\n",
      "Epoch:[66/80]\n",
      "Train MSE: 61.214337358266334 Mean loss: 61.215185063830496 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 61.269865215949295\n",
      "Eval Best MSE: 61.26975086535342\n",
      "Epoch:[67/80]\n",
      "Train MSE: 61.21430705063108 Mean loss: 61.21342489705283 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 61.269691283818396\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[68/80]\n",
      "Train MSE: 61.21429487341525 Mean loss: 61.21391216255504 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 61.26972233203884\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[69/80]\n",
      "Train MSE: 61.21427423241428 Mean loss: 61.21427876286253 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 61.269740348474386\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[70/80]\n",
      "Train MSE: 61.214270930048194 Mean loss: 61.21035801588431 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 61.269725496134754\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[71/80]\n",
      "Train MSE: 61.21424807062148 Mean loss: 61.215973791991466 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 61.26970315835143\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[72/80]\n",
      "Train MSE: 61.21424625620344 Mean loss: 61.212280956245735 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 61.269715842960764\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[73/80]\n",
      "Train MSE: 61.21423248395105 Mean loss: 61.21297037813085 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 61.269708752676245\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[74/80]\n",
      "Train MSE: 61.21422887363934 Mean loss: 61.213797332267085 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 61.26978788329988\n",
      "Eval Best MSE: 61.269691283818396\n",
      "Epoch:[75/80]\n",
      "Train MSE: 61.2142197315976 Mean loss: 61.21095831718671 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 61.26965943398936\n",
      "Eval Best MSE: 61.26965943398936\n",
      "Epoch:[76/80]\n",
      "Train MSE: 61.214209312079944 Mean loss: 61.21102454958583 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 61.269647127603804\n",
      "Eval Best MSE: 61.269647127603804\n",
      "Epoch:[77/80]\n",
      "Train MSE: 61.214208163304306 Mean loss: 61.21680062762379 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 61.26964125102245\n",
      "Eval Best MSE: 61.26964125102245\n",
      "Epoch:[78/80]\n",
      "Train MSE: 61.21419872787181 Mean loss: 61.21084880264553 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 61.26967986371841\n",
      "Eval Best MSE: 61.26964125102245\n",
      "Epoch:[79/80]\n",
      "Train MSE: 61.21418479966186 Mean loss: 61.21464608547956 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 61.26968457175765\n",
      "Eval Best MSE: 61.26964125102245\n",
      "Epoch:[80/80]\n",
      "Train MSE: 61.214188359163856 Mean loss: 61.213241498145834 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 61.26965260338086\n",
      "Eval Best MSE: 61.26964125102245\n",
      "Best Train MSE: 61.21418479966186\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_snr.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_device(设备判断)\n",
    "\n",
    "`BEST ACC@1：87.8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/device', 'config': 'config/train_device.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_device', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 4}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 43.41725357907785 Mean loss: 43.42885120358088 LR: [0.00095]\n",
      "Eval MSE: 41.98722525627314\n",
      "Eval Best MSE: 41.98722525627314\n",
      "Epoch:[2/80]\n",
      "Train MSE: 42.144681620523414 Mean loss: 42.15041881324971 LR: [0.0009025]\n",
      "Eval MSE: 41.98158288716476\n",
      "Eval Best MSE: 41.98158288716476\n",
      "Epoch:[3/80]\n",
      "Train MSE: 42.0841861908774 Mean loss: 42.09593274952036 LR: [0.000857375]\n",
      "Eval MSE: 41.910465934829624\n",
      "Eval Best MSE: 41.910465934829624\n",
      "Epoch:[4/80]\n",
      "Train MSE: 42.06131452017264 Mean loss: 42.06685400431135 LR: [0.0008145062499999999]\n",
      "Eval MSE: 41.90418956388247\n",
      "Eval Best MSE: 41.90418956388247\n",
      "Epoch:[5/80]\n",
      "Train MSE: 42.058861046353435 Mean loss: 42.05440345696643 LR: [0.0007737809374999998]\n",
      "Eval MSE: 41.90225220996717\n",
      "Eval Best MSE: 41.90225220996717\n",
      "Epoch:[6/80]\n",
      "Train MSE: 42.05807135109268 Mean loss: 42.058085061807546 LR: [0.0007350918906249997]\n",
      "Eval MSE: 41.90383242608175\n",
      "Eval Best MSE: 41.90225220996717\n",
      "Epoch:[7/80]\n",
      "Train MSE: 42.0578993644807 Mean loss: 42.064506108781934 LR: [0.0006983372960937497]\n",
      "Eval MSE: 41.903176611456836\n",
      "Eval Best MSE: 41.90225220996717\n",
      "Epoch:[8/80]\n",
      "Train MSE: 42.05777302482994 Mean loss: 42.05199039087886 LR: [0.0006634204312890621]\n",
      "Eval MSE: 41.901362581073116\n",
      "Eval Best MSE: 41.901362581073116\n",
      "Epoch:[9/80]\n",
      "Train MSE: 42.0575711446465 Mean loss: 42.06275651307232 LR: [0.000630249409724609]\n",
      "Eval MSE: 41.90248195550815\n",
      "Eval Best MSE: 41.901362581073116\n",
      "Epoch:[10/80]\n",
      "Train MSE: 42.0573677920402 Mean loss: 42.050910392693716 LR: [0.0005987369392383785]\n",
      "Eval MSE: 41.90126944064565\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[11/80]\n",
      "Train MSE: 42.05723981404115 Mean loss: 42.05279456619668 LR: [0.0005688000922764595]\n",
      "Eval MSE: 41.902396126936594\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[12/80]\n",
      "Train MSE: 42.057237041472064 Mean loss: 42.05153212083125 LR: [0.0005403600876626365]\n",
      "Eval MSE: 41.9019109702666\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[13/80]\n",
      "Train MSE: 42.057407952347354 Mean loss: 42.06223864259973 LR: [0.0005133420832795047]\n",
      "Eval MSE: 41.90321416992458\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[14/80]\n",
      "Train MSE: 42.0575234438618 Mean loss: 42.047075035297766 LR: [0.00048767497911552944]\n",
      "Eval MSE: 41.903258282389416\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[15/80]\n",
      "Train MSE: 42.05741493047793 Mean loss: 42.05904126800267 LR: [0.00046329123015975297]\n",
      "Eval MSE: 41.90141684630603\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[16/80]\n",
      "Train MSE: 42.057161586151494 Mean loss: 42.05680227701643 LR: [0.0004401266686517653]\n",
      "Eval MSE: 41.90133272820916\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[17/80]\n",
      "Train MSE: 42.05711824362203 Mean loss: 42.04546849073562 LR: [0.00041812033521917703]\n",
      "Eval MSE: 41.9034735735725\n",
      "Eval Best MSE: 41.90126944064565\n",
      "Epoch:[18/80]\n",
      "Train MSE: 42.05728931962886 Mean loss: 42.03884474155122 LR: [0.00039721431845821814]\n",
      "Eval MSE: 41.90106423448908\n",
      "Eval Best MSE: 41.90106423448908\n",
      "Epoch:[19/80]\n",
      "Train MSE: 42.05689290576291 Mean loss: 42.05439540559212 LR: [0.0003773536025353072]\n",
      "Eval MSE: 41.902219715181914\n",
      "Eval Best MSE: 41.90106423448908\n",
      "Epoch:[20/80]\n",
      "Train MSE: 42.05708293722935 Mean loss: 42.05177173783294 LR: [0.0003584859224085418]\n",
      "Eval MSE: 41.90163287841255\n",
      "Eval Best MSE: 41.90106423448908\n",
      "Epoch:[21/80]\n",
      "Train MSE: 42.0569270427385 Mean loss: 42.05742938961603 LR: [0.0003405616262881147]\n",
      "Eval MSE: 41.90121711028138\n",
      "Eval Best MSE: 41.90106423448908\n",
      "Epoch:[22/80]\n",
      "Train MSE: 42.0570110454685 Mean loss: 42.04765981488523 LR: [0.00032353354497370894]\n",
      "Eval MSE: 41.90098036618926\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[23/80]\n",
      "Train MSE: 42.05690272764907 Mean loss: 42.05751197949975 LR: [0.00030735686772502346]\n",
      "Eval MSE: 41.90123497288711\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[24/80]\n",
      "Train MSE: 42.056917172424335 Mean loss: 42.05533719695775 LR: [0.00029198902433877225]\n",
      "Eval MSE: 41.902279666473014\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[25/80]\n",
      "Train MSE: 42.056936781794256 Mean loss: 42.06493365870113 LR: [0.00027738957312183364]\n",
      "Eval MSE: 41.90125538426948\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[26/80]\n",
      "Train MSE: 42.057082167674054 Mean loss: 42.0670872072203 LR: [0.0002635200944657419]\n",
      "Eval MSE: 41.901317524460126\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[27/80]\n",
      "Train MSE: 42.05684723683707 Mean loss: 42.06365121149384 LR: [0.0002503440897424548]\n",
      "Eval MSE: 41.90132564498106\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[28/80]\n",
      "Train MSE: 42.05679617149732 Mean loss: 42.07611949886896 LR: [0.00023782688525533205]\n",
      "Eval MSE: 41.90162545224273\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[29/80]\n",
      "Train MSE: 42.056830075859736 Mean loss: 42.05880085767898 LR: [0.00022593554099256544]\n",
      "Eval MSE: 41.90107553886388\n",
      "Eval Best MSE: 41.90098036618926\n",
      "Epoch:[30/80]\n",
      "Train MSE: 42.05676122950548 Mean loss: 42.06002762043371 LR: [0.00021463876394293716]\n",
      "Eval MSE: 41.900892535007486\n",
      "Eval Best MSE: 41.900892535007486\n",
      "Epoch:[31/80]\n",
      "Train MSE: 42.05663342060747 Mean loss: 42.05231060601969 LR: [0.0002039068257457903]\n",
      "Eval MSE: 41.90101405068587\n",
      "Eval Best MSE: 41.900892535007486\n",
      "Epoch:[32/80]\n",
      "Train MSE: 42.05670666914618 Mean loss: 42.067516799521655 LR: [0.00019371148445850077]\n",
      "Eval MSE: 41.901628187308695\n",
      "Eval Best MSE: 41.900892535007486\n",
      "Epoch:[33/80]\n",
      "Train MSE: 42.05678113050193 Mean loss: 42.05497535773083 LR: [0.00018402591023557573]\n",
      "Eval MSE: 41.90111690779505\n",
      "Eval Best MSE: 41.900892535007486\n",
      "Epoch:[34/80]\n",
      "Train MSE: 42.05664546700596 Mean loss: 42.04918672342216 LR: [0.00017482461472379692]\n",
      "Eval MSE: 41.90150413978907\n",
      "Eval Best MSE: 41.900892535007486\n",
      "Epoch:[35/80]\n",
      "Train MSE: 42.056612845588546 Mean loss: 42.06580879413976 LR: [0.00016608338398760707]\n",
      "Eval MSE: 41.90082434464771\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[36/80]\n",
      "Train MSE: 42.056583699078516 Mean loss: 42.054389751062985 LR: [0.0001577792147882267]\n",
      "Eval MSE: 41.90178494553984\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[37/80]\n",
      "Train MSE: 42.05660243145178 Mean loss: 42.05754592355374 LR: [0.00014989025404881537]\n",
      "Eval MSE: 41.90110531128472\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[38/80]\n",
      "Train MSE: 42.0566398366557 Mean loss: 42.04907229938338 LR: [0.00014239574134637458]\n",
      "Eval MSE: 41.90111563340673\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[39/80]\n",
      "Train MSE: 42.056596190326545 Mean loss: 42.06294426031872 LR: [0.00013527595427905584]\n",
      "Eval MSE: 41.901044106774535\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[40/80]\n",
      "Train MSE: 42.05650374286505 Mean loss: 42.05426595907296 LR: [0.00012851215656510304]\n",
      "Eval MSE: 41.901130858325004\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[41/80]\n",
      "Train MSE: 42.056565417906 Mean loss: 42.051674125468836 LR: [0.00012208654873684788]\n",
      "Eval MSE: 41.901362890144036\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[42/80]\n",
      "Train MSE: 42.05658660793404 Mean loss: 42.0562736376197 LR: [0.00011598222130000548]\n",
      "Eval MSE: 41.901536122278685\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[43/80]\n",
      "Train MSE: 42.05648003775669 Mean loss: 42.0542372813267 LR: [0.00011018311023500519]\n",
      "Eval MSE: 41.901438350021245\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[44/80]\n",
      "Train MSE: 42.05652741595271 Mean loss: 42.05040578926559 LR: [0.00010467395472325493]\n",
      "Eval MSE: 41.90096661465017\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[45/80]\n",
      "Train MSE: 42.056460431297744 Mean loss: 42.06593572565939 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 41.90104049106814\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[46/80]\n",
      "Train MSE: 42.056458553191156 Mean loss: 42.061278334761084 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 41.90086731820736\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[47/80]\n",
      "Train MSE: 42.056505367187754 Mean loss: 42.04216540176257 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 41.9008534989267\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[48/80]\n",
      "Train MSE: 42.05644068828772 Mean loss: 42.044298610856046 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 41.90090195955368\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[49/80]\n",
      "Train MSE: 42.05647848118026 Mean loss: 42.056107748926216 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 41.90091587621284\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[50/80]\n",
      "Train MSE: 42.05640638485742 Mean loss: 42.05352351095824 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 41.90090610025725\n",
      "Eval Best MSE: 41.90082434464771\n",
      "Epoch:[51/80]\n",
      "Train MSE: 42.05643682066368 Mean loss: 42.05804671228459 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 41.90077474511556\n",
      "Eval Best MSE: 41.90077474511556\n",
      "Epoch:[52/80]\n",
      "Train MSE: 42.05602636770618 Mean loss: 42.05254715100854 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 41.900423581274715\n",
      "Eval Best MSE: 41.900423581274715\n",
      "Epoch:[53/80]\n",
      "Train MSE: 42.05590727717108 Mean loss: 42.05482663517505 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 41.900364493688656\n",
      "Eval Best MSE: 41.900364493688656\n",
      "Epoch:[54/80]\n",
      "Train MSE: 42.055822194999514 Mean loss: 42.066732710441656 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 41.90035804130393\n",
      "Eval Best MSE: 41.90035804130393\n",
      "Epoch:[55/80]\n",
      "Train MSE: 42.055816333359246 Mean loss: 42.057459096992964 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 41.900256674509336\n",
      "Eval Best MSE: 41.900256674509336\n",
      "Epoch:[56/80]\n",
      "Train MSE: 42.0557992644745 Mean loss: 42.05542550888737 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 41.90025234328258\n",
      "Eval Best MSE: 41.90025234328258\n",
      "Epoch:[57/80]\n",
      "Train MSE: 42.05579978395079 Mean loss: 42.07233781730179 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 41.90028397436279\n",
      "Eval Best MSE: 41.90025234328258\n",
      "Epoch:[58/80]\n",
      "Train MSE: 42.05576693706532 Mean loss: 42.05789891808434 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 41.9003846129355\n",
      "Eval Best MSE: 41.90025234328258\n",
      "Epoch:[59/80]\n",
      "Train MSE: 42.05575410232253 Mean loss: 42.052893714567205 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 41.900339729910286\n",
      "Eval Best MSE: 41.90025234328258\n",
      "Epoch:[60/80]\n",
      "Train MSE: 42.05574993380978 Mean loss: 42.07287275263693 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 41.90022684704847\n",
      "Eval Best MSE: 41.90022684704847\n",
      "Epoch:[61/80]\n",
      "Train MSE: 42.05577177774811 Mean loss: 42.059844228018704 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 41.90028271267602\n",
      "Eval Best MSE: 41.90022684704847\n",
      "Epoch:[62/80]\n",
      "Train MSE: 42.05571820447315 Mean loss: 42.059157228047866 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 41.90038360951346\n",
      "Eval Best MSE: 41.90022684704847\n",
      "Epoch:[63/80]\n",
      "Train MSE: 42.05573133639978 Mean loss: 42.06076318183831 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 41.900225030727576\n",
      "Eval Best MSE: 41.900225030727576\n",
      "Epoch:[64/80]\n",
      "Train MSE: 42.05570482723092 Mean loss: 42.04898928751987 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 41.90043068990591\n",
      "Eval Best MSE: 41.900225030727576\n",
      "Epoch:[65/80]\n",
      "Train MSE: 42.05350606774771 Mean loss: 42.05351093596062 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 41.89509636289404\n",
      "Eval Best MSE: 41.89509636289404\n",
      "Epoch:[66/80]\n",
      "Train MSE: 42.04988861057521 Mean loss: 42.064000475723134 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 41.89452580950501\n",
      "Eval Best MSE: 41.89452580950501\n",
      "Epoch:[67/80]\n",
      "Train MSE: 42.049674558292196 Mean loss: 42.06212055577641 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 41.89443168682475\n",
      "Eval Best MSE: 41.89443168682475\n",
      "Epoch:[68/80]\n",
      "Train MSE: 42.0494376061817 Mean loss: 42.042163139950915 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 41.894153569567614\n",
      "Eval Best MSE: 41.894153569567614\n",
      "Epoch:[69/80]\n",
      "Train MSE: 42.0492907664034 Mean loss: 42.05167770385742 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 41.89415080063086\n",
      "Eval Best MSE: 41.89415080063086\n",
      "Epoch:[70/80]\n",
      "Train MSE: 42.04921968839171 Mean loss: 42.03711163681165 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 41.8940298480543\n",
      "Eval Best MSE: 41.8940298480543\n",
      "Epoch:[71/80]\n",
      "Train MSE: 42.04908721876194 Mean loss: 42.046138510239864 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 41.89380330753644\n",
      "Eval Best MSE: 41.89380330753644\n",
      "Epoch:[72/80]\n",
      "Train MSE: 42.04896452629521 Mean loss: 42.043964234073606 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 41.89374269999886\n",
      "Eval Best MSE: 41.89374269999886\n",
      "Epoch:[73/80]\n",
      "Train MSE: 42.048878825938914 Mean loss: 42.05194312914283 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 41.89359412156252\n",
      "Eval Best MSE: 41.89359412156252\n",
      "Epoch:[74/80]\n",
      "Train MSE: 42.04873350251271 Mean loss: 42.033991011898074 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 41.89349300033112\n",
      "Eval Best MSE: 41.89349300033112\n",
      "Epoch:[75/80]\n",
      "Train MSE: 42.04859944375654 Mean loss: 42.0463825833481 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 41.893375731202525\n",
      "Eval Best MSE: 41.893375731202525\n",
      "Epoch:[76/80]\n",
      "Train MSE: 42.04842153913727 Mean loss: 42.05662312127848 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 41.89338364849874\n",
      "Eval Best MSE: 41.893375731202525\n",
      "Epoch:[77/80]\n",
      "Train MSE: 42.04822431042341 Mean loss: 42.042823892779055 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 41.89307968359809\n",
      "Eval Best MSE: 41.89307968359809\n",
      "Epoch:[78/80]\n",
      "Train MSE: 42.047835737659085 Mean loss: 42.04437537741872 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 41.89242409760097\n",
      "Eval Best MSE: 41.89242409760097\n",
      "Epoch:[79/80]\n",
      "Train MSE: 42.04706874719065 Mean loss: 42.02872607138305 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 41.891291831098044\n",
      "Eval Best MSE: 41.891291831098044\n",
      "Epoch:[80/80]\n",
      "Train MSE: 42.04490630473687 Mean loss: 42.03475855937046 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 41.88784167663371\n",
      "Eval Best MSE: 41.88784167663371\n",
      "Best Train MSE: 42.04490630473687\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_device.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_label(label判断)\n",
    "\n",
    "`BEST ACC@1：88.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'work_dir': './work_dir/label', 'config': 'config/train_label.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'feeder': 'feeder.Feeder_label', 'num_worker': 8, 'train_feeder_args': {'data_path': './data/train.pkl', 'snr': 0}, 'test_feeder_args': {'data_path': './data/test.pkl', 'snr': 0}, 'model': 'net.CNN', 'model_args': {'channels': 13, 'num_classes': 2}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'step': [10, 50], 'device': 0, 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 80, 'weight_decay': 1e-05}\n",
      "\n",
      "Epoch:[1/80]\n",
      "Train MSE: 43.52810120465149 Mean loss: 43.52788150416011 LR: [0.00095]\n",
      "Eval MSE: 41.95446320934909\n",
      "Eval Best MSE: 41.95446320934909\n",
      "Epoch:[2/80]\n",
      "Train MSE: 42.09201774822107 Mean loss: 42.08523043067054 LR: [0.0009025]\n",
      "Eval MSE: 41.88595199161576\n",
      "Eval Best MSE: 41.88595199161576\n",
      "Epoch:[3/80]\n",
      "Train MSE: 42.03074099103734 Mean loss: 42.019047256064624 LR: [0.000857375]\n",
      "Eval MSE: 41.8685816850567\n",
      "Eval Best MSE: 41.8685816850567\n",
      "Epoch:[4/80]\n",
      "Train MSE: 42.0255063231935 Mean loss: 42.042329146798735 LR: [0.0008145062499999999]\n",
      "Eval MSE: 41.868073038996656\n",
      "Eval Best MSE: 41.868073038996656\n",
      "Epoch:[5/80]\n",
      "Train MSE: 42.0248527796782 Mean loss: 42.02949593130466 LR: [0.0007737809374999998]\n",
      "Eval MSE: 41.868294287204215\n",
      "Eval Best MSE: 41.868073038996656\n",
      "Epoch:[6/80]\n",
      "Train MSE: 42.02476724074857 Mean loss: 42.03103283232292 LR: [0.0007350918906249997]\n",
      "Eval MSE: 41.86728943836411\n",
      "Eval Best MSE: 41.86728943836411\n",
      "Epoch:[7/80]\n",
      "Train MSE: 42.02466518284338 Mean loss: 42.02308968738117 LR: [0.0006983372960937497]\n",
      "Eval MSE: 41.86965372083454\n",
      "Eval Best MSE: 41.86728943836411\n",
      "Epoch:[8/80]\n",
      "Train MSE: 42.02453304506448 Mean loss: 42.02435052922342 LR: [0.0006634204312890621]\n",
      "Eval MSE: 41.868903813166305\n",
      "Eval Best MSE: 41.86728943836411\n",
      "Epoch:[9/80]\n",
      "Train MSE: 42.02465756191713 Mean loss: 42.02080552767863 LR: [0.000630249409724609]\n",
      "Eval MSE: 41.867441814562326\n",
      "Eval Best MSE: 41.86728943836411\n",
      "Epoch:[10/80]\n",
      "Train MSE: 42.02395501641238 Mean loss: 42.02606839205311 LR: [0.0005987369392383785]\n",
      "Eval MSE: 41.86830398271669\n",
      "Eval Best MSE: 41.86728943836411\n",
      "Epoch:[11/80]\n",
      "Train MSE: 42.02331360371378 Mean loss: 42.03178193083907 LR: [0.0005688000922764595]\n",
      "Eval MSE: 41.865722525000706\n",
      "Eval Best MSE: 41.865722525000706\n",
      "Epoch:[12/80]\n",
      "Train MSE: 42.019831512853415 Mean loss: 42.017787258181954 LR: [0.0005403600876626365]\n",
      "Eval MSE: 41.86115645515535\n",
      "Eval Best MSE: 41.86115645515535\n",
      "Epoch:[13/80]\n",
      "Train MSE: 42.01510907827133 Mean loss: 42.00018450644164 LR: [0.0005133420832795047]\n",
      "Eval MSE: 41.85714574341769\n",
      "Eval Best MSE: 41.85714574341769\n",
      "Epoch:[14/80]\n",
      "Train MSE: 42.01294739716921 Mean loss: 42.01862544507052 LR: [0.00048767497911552944]\n",
      "Eval MSE: 41.84868250941066\n",
      "Eval Best MSE: 41.84868250941066\n",
      "Epoch:[15/80]\n",
      "Train MSE: 41.99962408546768 Mean loss: 42.001491614147625 LR: [0.00046329123015975297]\n",
      "Eval MSE: 41.84157387397927\n",
      "Eval Best MSE: 41.84157387397927\n",
      "Epoch:[16/80]\n",
      "Train MSE: 41.99833490515268 Mean loss: 41.98632397271891 LR: [0.0004401266686517653]\n",
      "Eval MSE: 41.842387543402026\n",
      "Eval Best MSE: 41.84157387397927\n",
      "Epoch:[17/80]\n",
      "Train MSE: 41.99794855107874 Mean loss: 42.00269398647072 LR: [0.00041812033521917703]\n",
      "Eval MSE: 41.84009371216633\n",
      "Eval Best MSE: 41.84009371216633\n",
      "Epoch:[18/80]\n",
      "Train MSE: 41.99762496339584 Mean loss: 41.99642280983714 LR: [0.00039721431845821814]\n",
      "Eval MSE: 41.8401803494029\n",
      "Eval Best MSE: 41.84009371216633\n",
      "Epoch:[19/80]\n",
      "Train MSE: 41.99737580954677 Mean loss: 42.00598946292843 LR: [0.0003773536025353072]\n",
      "Eval MSE: 41.84071408524762\n",
      "Eval Best MSE: 41.84009371216633\n",
      "Epoch:[20/80]\n",
      "Train MSE: 41.996773559221 Mean loss: 41.99039835634485 LR: [0.0003584859224085418]\n",
      "Eval MSE: 41.838521620806524\n",
      "Eval Best MSE: 41.838521620806524\n",
      "Epoch:[21/80]\n",
      "Train MSE: 41.99565995474718 Mean loss: 41.993754125274386 LR: [0.0003405616262881147]\n",
      "Eval MSE: 41.83757976316056\n",
      "Eval Best MSE: 41.83757976316056\n",
      "Epoch:[22/80]\n",
      "Train MSE: 41.99497377393645 Mean loss: 41.98672222036176 LR: [0.00032353354497370894]\n",
      "Eval MSE: 41.83741493098082\n",
      "Eval Best MSE: 41.83741493098082\n",
      "Epoch:[23/80]\n",
      "Train MSE: 41.99458838948102 Mean loss: 41.99457075743549 LR: [0.00030735686772502346]\n",
      "Eval MSE: 41.83672723547865\n",
      "Eval Best MSE: 41.83672723547865\n",
      "Epoch:[24/80]\n",
      "Train MSE: 41.99431005895365 Mean loss: 42.011963076296105 LR: [0.00029198902433877225]\n",
      "Eval MSE: 41.8367237298523\n",
      "Eval Best MSE: 41.8367237298523\n",
      "Epoch:[25/80]\n",
      "Train MSE: 41.99410892689017 Mean loss: 41.996083960068965 LR: [0.00027738957312183364]\n",
      "Eval MSE: 41.837165311756195\n",
      "Eval Best MSE: 41.8367237298523\n",
      "Epoch:[26/80]\n",
      "Train MSE: 41.99404696472147 Mean loss: 41.98319934743696 LR: [0.0002635200944657419]\n",
      "Eval MSE: 41.83664059400823\n",
      "Eval Best MSE: 41.83664059400823\n",
      "Epoch:[27/80]\n",
      "Train MSE: 41.99407534485181 Mean loss: 41.990112726667284 LR: [0.0002503440897424548]\n",
      "Eval MSE: 41.83626330732373\n",
      "Eval Best MSE: 41.83626330732373\n",
      "Epoch:[28/80]\n",
      "Train MSE: 41.993910872518626 Mean loss: 42.004459381103516 LR: [0.00023782688525533205]\n",
      "Eval MSE: 41.83662075842922\n",
      "Eval Best MSE: 41.83626330732373\n",
      "Epoch:[29/80]\n",
      "Train MSE: 41.99401206718812 Mean loss: 41.9887963522852 LR: [0.00022593554099256544]\n",
      "Eval MSE: 41.83665242761407\n",
      "Eval Best MSE: 41.83626330732373\n",
      "Epoch:[30/80]\n",
      "Train MSE: 41.99391667620407 Mean loss: 41.99841885862097 LR: [0.00021463876394293716]\n",
      "Eval MSE: 41.83622512648029\n",
      "Eval Best MSE: 41.83622512648029\n",
      "Epoch:[31/80]\n",
      "Train MSE: 41.99390186755723 Mean loss: 41.996754992324696 LR: [0.0002039068257457903]\n",
      "Eval MSE: 41.836583449758514\n",
      "Eval Best MSE: 41.83622512648029\n",
      "Epoch:[32/80]\n",
      "Train MSE: 41.9937104057447 Mean loss: 41.99612160066588 LR: [0.00019371148445850077]\n",
      "Eval MSE: 41.83617223301421\n",
      "Eval Best MSE: 41.83617223301421\n",
      "Epoch:[33/80]\n",
      "Train MSE: 41.99374776781329 Mean loss: 41.98713621629023 LR: [0.00018402591023557573]\n",
      "Eval MSE: 41.83601171512583\n",
      "Eval Best MSE: 41.83601171512583\n",
      "Epoch:[34/80]\n",
      "Train MSE: 41.99359452892334 Mean loss: 41.997491397688876 LR: [0.00017482461472379692]\n",
      "Eval MSE: 41.83623272623788\n",
      "Eval Best MSE: 41.83601171512583\n",
      "Epoch:[35/80]\n",
      "Train MSE: 41.99355530886033 Mean loss: 41.982084291171184 LR: [0.00016608338398760707]\n",
      "Eval MSE: 41.83606828780603\n",
      "Eval Best MSE: 41.83601171512583\n",
      "Epoch:[36/80]\n",
      "Train MSE: 41.993596103759515 Mean loss: 41.98075142581906 LR: [0.0001577792147882267]\n",
      "Eval MSE: 41.836898278713754\n",
      "Eval Best MSE: 41.83601171512583\n",
      "Epoch:[37/80]\n",
      "Train MSE: 41.99356723432114 Mean loss: 41.99722420008837 LR: [0.00014989025404881537]\n",
      "Eval MSE: 41.83621314045592\n",
      "Eval Best MSE: 41.83601171512583\n",
      "Epoch:[38/80]\n",
      "Train MSE: 41.99342967869298 Mean loss: 41.99467353483217 LR: [0.00014239574134637458]\n",
      "Eval MSE: 41.83589363733222\n",
      "Eval Best MSE: 41.83589363733222\n",
      "Epoch:[39/80]\n",
      "Train MSE: 41.993431851072444 Mean loss: 41.98375119572192 LR: [0.00013527595427905584]\n",
      "Eval MSE: 41.83588602910693\n",
      "Eval Best MSE: 41.83588602910693\n",
      "Epoch:[40/80]\n",
      "Train MSE: 41.99338135284307 Mean loss: 41.97845995742663 LR: [0.00012851215656510304]\n",
      "Eval MSE: 41.83587732854879\n",
      "Eval Best MSE: 41.83587732854879\n",
      "Epoch:[41/80]\n",
      "Train MSE: 41.99332690204219 Mean loss: 41.99921894917446 LR: [0.00012208654873684788]\n",
      "Eval MSE: 41.83567083530235\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[42/80]\n",
      "Train MSE: 41.99338192842175 Mean loss: 41.99199592117715 LR: [0.00011598222130000548]\n",
      "Eval MSE: 41.83577747323802\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[43/80]\n",
      "Train MSE: 41.99325959347537 Mean loss: 41.992862465107336 LR: [0.00011018311023500519]\n",
      "Eval MSE: 41.83610948314942\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[44/80]\n",
      "Train MSE: 41.99322600720287 Mean loss: 41.985750890411104 LR: [0.00010467395472325493]\n",
      "Eval MSE: 41.83589586857024\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[45/80]\n",
      "Train MSE: 41.99323793398685 Mean loss: 41.99731092537399 LR: [9.944025698709218e-05]\n",
      "Eval MSE: 41.83571394434515\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[46/80]\n",
      "Train MSE: 41.99322043242572 Mean loss: 41.993977808319364 LR: [9.446824413773756e-05]\n",
      "Eval MSE: 41.835886295839366\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[47/80]\n",
      "Train MSE: 41.99316345807624 Mean loss: 42.01015060559838 LR: [8.974483193085068e-05]\n",
      "Eval MSE: 41.83572229349388\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[48/80]\n",
      "Train MSE: 41.99314870685494 Mean loss: 41.995366290607286 LR: [8.525759033430814e-05]\n",
      "Eval MSE: 41.835761181389984\n",
      "Eval Best MSE: 41.83567083530235\n",
      "Epoch:[49/80]\n",
      "Train MSE: 41.99315533937367 Mean loss: 41.982820831568894 LR: [8.099471081759274e-05]\n",
      "Eval MSE: 41.8356703653452\n",
      "Eval Best MSE: 41.8356703653452\n",
      "Epoch:[50/80]\n",
      "Train MSE: 41.993058043290375 Mean loss: 41.98788938269151 LR: [7.69449752767131e-05]\n",
      "Eval MSE: 41.835618314414916\n",
      "Eval Best MSE: 41.835618314414916\n",
      "Epoch:[51/80]\n",
      "Train MSE: 41.99296502845386 Mean loss: 41.987003680879035 LR: [7.309772651287744e-05]\n",
      "Eval MSE: 41.83563576633737\n",
      "Eval Best MSE: 41.835618314414916\n",
      "Epoch:[52/80]\n",
      "Train MSE: 41.99294200133748 Mean loss: 41.99774630723801 LR: [6.944284018723356e-05]\n",
      "Eval MSE: 41.83540194360054\n",
      "Eval Best MSE: 41.83540194360054\n",
      "Epoch:[53/80]\n",
      "Train MSE: 41.992910787772274 Mean loss: 41.99010727468845 LR: [6.597069817787189e-05]\n",
      "Eval MSE: 41.835481895590725\n",
      "Eval Best MSE: 41.83540194360054\n",
      "Epoch:[54/80]\n",
      "Train MSE: 41.99284961738812 Mean loss: 42.006494859678554 LR: [6.267216326897829e-05]\n",
      "Eval MSE: 41.83524999925484\n",
      "Eval Best MSE: 41.83524999925484\n",
      "Epoch:[55/80]\n",
      "Train MSE: 41.99268750241346 Mean loss: 41.98661581393892 LR: [5.953855510552937e-05]\n",
      "Eval MSE: 41.83510509156493\n",
      "Eval Best MSE: 41.83510509156493\n",
      "Epoch:[56/80]\n",
      "Train MSE: 41.99258492079783 Mean loss: 41.992977885018405 LR: [5.65616273502529e-05]\n",
      "Eval MSE: 41.835331780267474\n",
      "Eval Best MSE: 41.83510509156493\n",
      "Epoch:[57/80]\n",
      "Train MSE: 41.99248938929319 Mean loss: 41.998621206367964 LR: [5.373354598274025e-05]\n",
      "Eval MSE: 41.83493768520546\n",
      "Eval Best MSE: 41.83493768520546\n",
      "Epoch:[58/80]\n",
      "Train MSE: 41.992347428834236 Mean loss: 41.98652356915769 LR: [5.104686868360323e-05]\n",
      "Eval MSE: 41.83487158213286\n",
      "Eval Best MSE: 41.83487158213286\n",
      "Epoch:[59/80]\n",
      "Train MSE: 41.99221278894208 Mean loss: 41.98445414652866 LR: [4.849452524942307e-05]\n",
      "Eval MSE: 41.83470954429296\n",
      "Eval Best MSE: 41.83470954429296\n",
      "Epoch:[60/80]\n",
      "Train MSE: 41.9919998682335 Mean loss: 41.995167808195134 LR: [4.606979898695191e-05]\n",
      "Eval MSE: 41.83442467828173\n",
      "Eval Best MSE: 41.83442467828173\n",
      "Epoch:[61/80]\n",
      "Train MSE: 41.99178390635247 Mean loss: 41.98380495594666 LR: [4.376630903760431e-05]\n",
      "Eval MSE: 41.834189369464156\n",
      "Eval Best MSE: 41.834189369464156\n",
      "Epoch:[62/80]\n",
      "Train MSE: 41.99157503057262 Mean loss: 41.985166650957765 LR: [4.157799358572409e-05]\n",
      "Eval MSE: 41.83406978018673\n",
      "Eval Best MSE: 41.83406978018673\n",
      "Epoch:[63/80]\n",
      "Train MSE: 41.99141774834174 Mean loss: 41.975927977435354 LR: [3.9499093906437885e-05]\n",
      "Eval MSE: 41.83385536964408\n",
      "Eval Best MSE: 41.83385536964408\n",
      "Epoch:[64/80]\n",
      "Train MSE: 41.99125589667779 Mean loss: 41.986725359891366 LR: [3.752413921111599e-05]\n",
      "Eval MSE: 41.8337714166673\n",
      "Eval Best MSE: 41.8337714166673\n",
      "Epoch:[65/80]\n",
      "Train MSE: 41.991110217848295 Mean loss: 41.98915275641247 LR: [3.564793225056019e-05]\n",
      "Eval MSE: 41.83372230826154\n",
      "Eval Best MSE: 41.83372230826154\n",
      "Epoch:[66/80]\n",
      "Train MSE: 41.99099772542953 Mean loss: 41.98953998194332 LR: [3.3865535638032174e-05]\n",
      "Eval MSE: 41.83349400222897\n",
      "Eval Best MSE: 41.83349400222897\n",
      "Epoch:[67/80]\n",
      "Train MSE: 41.990902640097595 Mean loss: 41.98593959977141 LR: [3.2172258856130564e-05]\n",
      "Eval MSE: 41.83346809954543\n",
      "Eval Best MSE: 41.83346809954543\n",
      "Epoch:[68/80]\n",
      "Train MSE: 41.99080616914271 Mean loss: 41.99080367636891 LR: [3.056364591332403e-05]\n",
      "Eval MSE: 41.83333733290864\n",
      "Eval Best MSE: 41.83333733290864\n",
      "Epoch:[69/80]\n",
      "Train MSE: 41.99074247124044 Mean loss: 41.993465811805386 LR: [2.903546361765783e-05]\n",
      "Eval MSE: 41.833349141111384\n",
      "Eval Best MSE: 41.83333733290864\n",
      "Epoch:[70/80]\n",
      "Train MSE: 41.99068270844384 Mean loss: 41.97841014693269 LR: [2.758369043677494e-05]\n",
      "Eval MSE: 41.83322567786281\n",
      "Eval Best MSE: 41.83322567786281\n",
      "Epoch:[71/80]\n",
      "Train MSE: 41.99062516777788 Mean loss: 41.98973026106843 LR: [2.620450591493619e-05]\n",
      "Eval MSE: 41.83317537127801\n",
      "Eval Best MSE: 41.83317537127801\n",
      "Epoch:[72/80]\n",
      "Train MSE: 41.990568421807424 Mean loss: 41.988195301157184 LR: [2.489428061918938e-05]\n",
      "Eval MSE: 41.833243417686944\n",
      "Eval Best MSE: 41.83317537127801\n",
      "Epoch:[73/80]\n",
      "Train MSE: 41.99052264120609 Mean loss: 41.98370913277685 LR: [2.364956658822991e-05]\n",
      "Eval MSE: 41.83314419321955\n",
      "Eval Best MSE: 41.83314419321955\n",
      "Epoch:[74/80]\n",
      "Train MSE: 41.99048393373889 Mean loss: 41.99123622252878 LR: [2.2467088258818413e-05]\n",
      "Eval MSE: 41.83305592595142\n",
      "Eval Best MSE: 41.83305592595142\n",
      "Epoch:[75/80]\n",
      "Train MSE: 41.99046231526862 Mean loss: 41.99430335728468 LR: [2.134373384587749e-05]\n",
      "Eval MSE: 41.833041916147586\n",
      "Eval Best MSE: 41.833041916147586\n",
      "Epoch:[76/80]\n",
      "Train MSE: 41.990424350364066 Mean loss: 41.98006545547891 LR: [2.0276547153583614e-05]\n",
      "Eval MSE: 41.833007372179786\n",
      "Eval Best MSE: 41.833007372179786\n",
      "Epoch:[77/80]\n",
      "Train MSE: 41.99040918075662 Mean loss: 41.99175966313455 LR: [1.9262719795904432e-05]\n",
      "Eval MSE: 41.83314215673855\n",
      "Eval Best MSE: 41.833007372179786\n",
      "Epoch:[78/80]\n",
      "Train MSE: 41.990373201664646 Mean loss: 41.99475409921292 LR: [1.829958380610921e-05]\n",
      "Eval MSE: 41.83296067283368\n",
      "Eval Best MSE: 41.83296067283368\n",
      "Epoch:[79/80]\n",
      "Train MSE: 41.99033402076745 Mean loss: 41.980747020350094 LR: [1.738460461580375e-05]\n",
      "Eval MSE: 41.83295630350229\n",
      "Eval Best MSE: 41.83295630350229\n",
      "Epoch:[80/80]\n",
      "Train MSE: 41.99031346400827 Mean loss: 42.00212537714865 LR: [1.6515374385013564e-05]\n",
      "Eval MSE: 41.83297027096764\n",
      "Eval Best MSE: 41.83295630350229\n",
      "Best Train MSE: 41.99031346400827\n"
     ]
    }
   ],
   "source": [
    "!python main.py --config config/train_label.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
